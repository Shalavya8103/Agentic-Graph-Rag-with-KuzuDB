{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kuzu\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PurchaseFrequency = pd.read_csv(\"PurchaseFrequency.csv\")\n",
    "\n",
    "df_ChurnRiskScore = pd.read_csv(\"ChurnRiskScore.csv\")\n",
    "\n",
    "df_CLTV = pd.read_csv(\"CLTV.csv\")\n",
    "\n",
    "df_AOV = pd.read_csv(\"AOV.csv\")\n",
    "\n",
    "df_Revenue = pd.read_csv(\"revenue.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_kuzu.graphs.kuzu_graph import KuzuGraph\n",
    "from langchain_kuzu.chains.graph_qa.kuzu import KuzuQAChain\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.tools import Tool\n",
    "from langgraph.prebuilt import create_react_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize database\n",
    "db = kuzu.Database(\"./knowledge_graph\")\n",
    "conn = kuzu.Connection(db)\n",
    "graph = KuzuGraph(db, allow_dangerous_requests=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM instance\n",
    "llm_groq=ChatGroq(\n",
    "    model=\"llama3-70b-8192\", \n",
    "    temperature=0.3, \n",
    "    api_key=\"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\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kuzu Tool\n",
    "qa_chain = KuzuQAChain.from_llm(\n",
    "    llm=llm_groq,\n",
    "    graph=graph,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True\n",
    ")\n",
    "\n",
    "kuzu_tool = Tool(\n",
    "    name=\"Kuzu Query Tool\",\n",
    "    description=\"A tool for querying the Kùzu graph database.\",\n",
    "    func=qa_chain.run,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Correlation tool\n",
    "# def calculate_correlation(metric, dimensions):\n",
    "#     mapping = {\n",
    "#     'Revenue': df_Revenue,\n",
    "#     'AOV': df_AOV,\n",
    "#     'CLTV':df_CLTV,\n",
    "#     'ChurnRiskScore':df_ChurnRiskScore,\n",
    "#     'PurchaseFrequency':df_PurchaseFrequency\n",
    "#     }\n",
    "#     if metric not in mapping:\n",
    "#         raise ValueError(f\"Metric '{metric}' not found in the mapping.\")\n",
    "    \n",
    "#     df = mapping[metric]\n",
    "    \n",
    "#     selected_columns = [metric] + [dim for dim in dimensions if dim in df.columns]\n",
    "    \n",
    "#     if len(selected_columns) < 2:\n",
    "#         raise ValueError(\"Not enough valid columns found in the DataFrame for correlation calculation.\")\n",
    "    \n",
    "#     df_selected = df[selected_columns].copy()\n",
    "    \n",
    "#     # Encoding non-numeric columns\n",
    "#     for col in df_selected.columns:\n",
    "#         if not pd.api.types.is_numeric_dtype(df_selected[col]):\n",
    "#             df_selected[col] = df_selected[col].astype('category').cat.codes\n",
    "    \n",
    "#     correlation_matrix = df_selected.corr()\n",
    "#     correlation_matrix.drop([metric],axis=1,inplace=True)\n",
    "#     return correlation_matrix.loc[metric]\n",
    "\n",
    "# def calculate_correlation_tool(input_str):\n",
    "#     \"\"\"\n",
    "#     Expects a JSON string with keys 'metric' and 'dimensions'. For example:\n",
    "#     {\"metric\": \"Revenue\", \"dimensions\": [\"Region\", \"Segment\", \"ProductCategory\"]}\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         data = json.loads(input_str)\n",
    "#         if isinstance(data, dict) and \"__arg1\" in data:\n",
    "#             inner_input = data[\"__arg1\"]\n",
    "#             # If inner_input is a string, try parsing it as JSON\n",
    "#             if isinstance(inner_input, str):\n",
    "#                 data = json.loads(inner_input)\n",
    "#             else:\n",
    "#                 data = inner_input\n",
    "#         metric = data.get(\"metric\")\n",
    "#         dimensions = data.get(\"dimensions\")\n",
    "#         if not metric or not dimensions:\n",
    "#             return \"Error: Input must contain both 'metric' and 'dimensions'.\"\n",
    "        \n",
    "#         result = calculate_correlation(metric, dimensions)\n",
    "#         return result.to_json()\n",
    "#     except Exception as e:\n",
    "#         return f\"Error: {str(e)}\"\n",
    "    \n",
    "# c_tool = Tool(\n",
    "    # name=\"calculate_correlation_tool\",\n",
    "    # description=(\n",
    "    #     \"A tool for calculating the correlation between a given metric and dimensions. \"\n",
    "    #     \"Input must be a JSON string with keys 'metric' and 'dimensions'. For example:\"\n",
    "    #     '{\"metric\":, \"dimensions\": []}'\n",
    "    # ),\n",
    "    # func=calculate_correlation_tool\n",
    "    # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller, grangercausalitytests\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import euclidean\n",
    "from dtaidistance import dtw\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def analyze_similarity_causality(input_str):\n",
    "    \"\"\"Analyzes similarity and causality for a given metric from time-series data.\"\"\"\n",
    "\n",
    "    # Parse JSON input safely\n",
    "    try:\n",
    "        data = json.loads(input_str)\n",
    "        if isinstance(data, dict) and \"__arg1\" in data:\n",
    "            data = json.loads(data[\"__arg1\"])\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"error\": \"Invalid JSON input.\"}\n",
    "\n",
    "    metric = data.get(\"metric\")\n",
    "    \n",
    "    # Mapping of available datasets\n",
    "    mapping = {\n",
    "        'Revenue': df_Revenue,\n",
    "        'AOV': df_AOV,\n",
    "        'CLTV': df_CLTV,\n",
    "        'ChurnRiskScore': df_ChurnRiskScore,\n",
    "        'PurchaseFrequency': df_PurchaseFrequency\n",
    "    }\n",
    "    \n",
    "    # Validate metric input\n",
    "    if metric not in mapping:\n",
    "        return {\"error\": f\"Metric '{metric}' not found in dataset mapping.\"}\n",
    "    \n",
    "    df_used = mapping[metric]\n",
    "\n",
    "    def check_stationarity(df_pair):\n",
    "        \"\"\"Check stationarity using ADF Test and apply differencing if needed.\"\"\"\n",
    "        try:\n",
    "            res1 = adfuller(df_pair.iloc[:, 0])  \n",
    "            res2 = adfuller(df_pair.iloc[:, 1])\n",
    "        except Exception:\n",
    "            return df_pair  # Return original if ADF fails\n",
    "\n",
    "        if res1[1] > 0.05 or res2[1] > 0.05:\n",
    "            return df_pair.diff().dropna()  # Apply differencing if needed\n",
    "        return df_pair  \n",
    "\n",
    "    cols = [col for col in df_used.columns if col not in [metric, 'day']]\n",
    "    \n",
    "    results = []\n",
    "    for col in cols:\n",
    "        df_pair = df_used[[metric, col]].dropna()\n",
    "        df_pair = check_stationarity(df_pair) \n",
    "        corr,corr_p_value= pearsonr(df_pair.iloc[:, 0], df_pair.iloc[:, 1])  # Pearson Correlation\n",
    "\n",
    "\n",
    "        # Compute Granger Causality\n",
    "        max_lags = 3\n",
    "        granger_results = grangercausalitytests(df_pair, max_lags, verbose=False)\n",
    "        granger_p_values = [granger_results[lag][0]['ssr_chi2test'][1] for lag in range(1, max_lags + 1)]\n",
    "        \n",
    "        best_granger_p = min(granger_p_values)\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            'Variable': col,\n",
    "            'Pearson Correlation': corr,\n",
    "            'Best Granger p-value': best_granger_p\n",
    "        })\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "\n",
    "            # # Compute Similarity Metrics\n",
    "            # try:\n",
    "            #     corr, corr_p_value = pearsonr(df_pair.iloc[:, 0], df_pair.iloc[:, 1])  \n",
    "            #     dtw_distance = dtw.distance(df_pair.iloc[:, 0], df_pair.iloc[:, 1])  \n",
    "            #     euclidean_distance = euclidean(df_pair.iloc[:, 0], df_pair.iloc[:, 1])  \n",
    "            # except Exception:\n",
    "            #     print(\"not done similarity\")\n",
    "            #     continue  # Skip variable if similarity calculation fails\n",
    "\n",
    "            # # Compute Granger Causality (safely extract p-values)\n",
    "            # max_lags = 3\n",
    "            # granger_p_values = []\n",
    "            \n",
    "            # try:\n",
    "            #     granger_results = grangercausalitytests(df_pair, max_lags, verbose=False)\n",
    "            #     for lag in range(1, max_lags + 1):\n",
    "            #         if lag in granger_results and 'ssr_chi2test' in granger_results[lag][0]:\n",
    "            #             p_value = granger_results[lag][0]['ssr_chi2test'][1]\n",
    "            #             granger_p_values.append(p_value)\n",
    "            # except Exception:\n",
    "            #     print(\"not done similarity\")\n",
    "\n",
    "            # best_granger_p = min(granger_p_values) if granger_p_values else 1.0  # Handle missing values\n",
    "\n",
    "            # Store results\n",
    "        #     results.append({\n",
    "        #         'Variable': col,\n",
    "        #         'Pearson Correlation': corr,\n",
    "        #         'Correlation p-value': corr_p_value,\n",
    "        #         'DTW Distance': dtw_distance,\n",
    "        #         'Euclidean Distance': euclidean_distance,\n",
    "        #         'Best Granger p-value': best_granger_p\n",
    "        #     })\n",
    "\n",
    "        # df_results = pd.DataFrame(results)\n",
    "\n",
    "    #Extract Top 2 variables by Pearson Correlation & Granger Causality\n",
    "    top_pearson = df_results.nlargest(2, 'Pearson Correlation')[['Variable', 'Pearson Correlation']]\n",
    "    top_granger = df_results.nsmallest(2, 'Best Granger p-value')[['Variable', 'Best Granger p-value']]\n",
    "    \n",
    "    return {\n",
    "        \"Top 2 Pearson Correlation Variables\": top_pearson.to_dict(orient='records'),\n",
    "        \"Top 2 Granger Causality Variables\": top_granger.to_dict(orient='records')\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = json.dumps({\"metric\": \"Revenue\"})  \n",
    "output = analyze_similarity_causality(sample_input)  \n",
    "print(output)  # Displays the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shalavyaagrawal/Documents/Kairos/.venv/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/home/shalavyaagrawal/Documents/Kairos/.venv/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/home/shalavyaagrawal/Documents/Kairos/.venv/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/home/shalavyaagrawal/Documents/Kairos/.venv/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/home/shalavyaagrawal/Documents/Kairos/.venv/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/home/shalavyaagrawal/Documents/Kairos/.venv/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/home/shalavyaagrawal/Documents/Kairos/.venv/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/home/shalavyaagrawal/Documents/Kairos/.venv/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/home/shalavyaagrawal/Documents/Kairos/.venv/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/home/shalavyaagrawal/Documents/Kairos/.venv/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/home/shalavyaagrawal/Documents/Kairos/.venv/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/home/shalavyaagrawal/Documents/Kairos/.venv/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/home/shalavyaagrawal/Documents/Kairos/.venv/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n",
      "/home/shalavyaagrawal/Documents/Kairos/.venv/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:1556: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Column 'Pearson Correlation' has dtype object, cannot use method 'nlargest' with this dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sample_input \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAOV\u001b[39m\u001b[38;5;124m\"\u001b[39m})  \n\u001b[0;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_similarity_causality\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_input\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)  \u001b[38;5;66;03m# Displays the results\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[58], line 110\u001b[0m, in \u001b[0;36manalyze_similarity_causality\u001b[0;34m(input_str)\u001b[0m\n\u001b[1;32m     71\u001b[0m df_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;66;03m# # Compute Similarity Metrics\u001b[39;00m\n\u001b[1;32m     74\u001b[0m         \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;66;03m#     corr, corr_p_value = pearsonr(df_pair.iloc[:, 0], df_pair.iloc[:, 1])  \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m \n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m#Extract Top 2 variables by Pearson Correlation & Granger Causality\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m top_pearson \u001b[38;5;241m=\u001b[39m \u001b[43mdf_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlargest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPearson Correlation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVariable\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPearson Correlation\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    111\u001b[0m top_granger \u001b[38;5;241m=\u001b[39m df_results\u001b[38;5;241m.\u001b[39mnsmallest(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Granger p-value\u001b[39m\u001b[38;5;124m'\u001b[39m)[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVariable\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Granger p-value\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop 2 Pearson Correlation Variables\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_pearson\u001b[38;5;241m.\u001b[39mto_dict(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop 2 Granger Causality Variables\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_granger\u001b[38;5;241m.\u001b[39mto_dict(orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    116\u001b[0m }\n",
      "File \u001b[0;32m~/Documents/Kairos/.venv/lib/python3.12/site-packages/pandas/core/frame.py:7644\u001b[0m, in \u001b[0;36mDataFrame.nlargest\u001b[0;34m(self, n, columns, keep)\u001b[0m\n\u001b[1;32m   7525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnlargest\u001b[39m(\n\u001b[1;32m   7526\u001b[0m     \u001b[38;5;28mself\u001b[39m, n: \u001b[38;5;28mint\u001b[39m, columns: IndexLabel, keep: NsmallestNlargestKeep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   7527\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   7528\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   7529\u001b[0m \u001b[38;5;124;03m    Return the first `n` rows ordered by `columns` in descending order.\u001b[39;00m\n\u001b[1;32m   7530\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   7642\u001b[0m \u001b[38;5;124;03m    Brunei      434000    12128      BN\u001b[39;00m\n\u001b[1;32m   7643\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 7644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mselectn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSelectNFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlargest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Kairos/.venv/lib/python3.12/site-packages/pandas/core/methods/selectn.py:57\u001b[0m, in \u001b[0;36mSelectN.nlargest\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnlargest\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnlargest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Kairos/.venv/lib/python3.12/site-packages/pandas/core/methods/selectn.py:201\u001b[0m, in \u001b[0;36mSelectNFrame.compute\u001b[0;34m(self, method)\u001b[0m\n\u001b[1;32m    199\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m frame[column]\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_valid_dtype_n_method(dtype):\n\u001b[0;32m--> 201\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    202\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(column)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot use method \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(method)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with this dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m         )\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_indexer\u001b[39m(current_indexer, other_indexer):\n\u001b[1;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m    Helper function to concat `current_indexer` and `other_indexer`\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m    depending on `method`\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Column 'Pearson Correlation' has dtype object, cannot use method 'nlargest' with this dtype"
     ]
    }
   ],
   "source": [
    "sample_input = json.dumps({\"metric\": \"AOV\"})  \n",
    "output = analyze_similarity_causality(sample_input)  \n",
    "print(output)  # Displays the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_similarity_causality_tool = Tool(\n",
    "    name=\"analyze_similarity_causality_tool\",\n",
    "    description=(\n",
    "        \"A tool for calculating the attributing change in a metric to certain dimension based in the pearson relation coefficient and granger p value \"\n",
    "        \"Input must be a JSON string with keys 'metric'. For example:\"\n",
    "        '{\"metric\"}'\n",
    "    ),\n",
    "    func=analyze_similarity_causality\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REACT AGENT\n",
    "prompt = (\n",
    "    \"You are an AI analyst specializing in data analytics for metrics and dimensions. Your goal is to provide clear, concise answers to the user queries. \"\n",
    "    \"When answering questions, you may internally use various tools to retrieve or analyze data, but you must not mention the names of these tools in your final answer. \"\n",
    "    \"Instead, simply provide the insights and data that directly address the user's query. \\n\\n\"\n",
    "    \n",
    "    \"Your job is to answer queries by choosing the most appropriate tool:\\n\\n\"\n",
    "    \n",
    "    \"1. Use the 'Kuzu Query Tool' for queries that request data retrieval or general insights about changes in metrics from the graph. \"\n",
    "    \"For example, if the query asks for 'changes in metrics for a certain' or 'what has happened', use the Kùzu Query Tool.\\n\\n\"\n",
    "    \n",
    "    \"2. Use the 'analyze_similarity_causality_tool' only when the query explicitly asks for the cause of a change in a metric.It is used to determine which variable caused the change in the metric. \"\n",
    "    \"In these cases,pass the metric to the analyze_similarity_causality_tool do not call the Kuzu Query Tool. \"\n",
    "    \"When calling the analyze_similarity_causality_tool, provide a JSON object with key 'metric'. For example: \"\n",
    "    '{\"metric\": \"Revenue\"}.\\n\\n'\n",
    "    \"It will return the a dictionary with a top 2 variables based on pearson correlation coeeficient and granger p_value\"\n",
    "    \"The higher coefficient the value the stronger the correlation, the smaller the p_value the more the causality\"\n",
    "    \"Always think step by step and decide which tool best suits the user's query. \"\n",
    "    \"If the query does not explicitly request a cause or relationship analysis, do not call the analyze_similarity_causality_tool.\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "agent = create_react_agent(\n",
    "    model=llm_groq,\n",
    "    tools=[kuzu_tool,analyze_similarity_causality_tool],\n",
    "    prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new KuzuQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (u:User {user_id: '1'})-[:Associated]->(m:Metrics) RETURN m.metric_id, m.metric_name, m.cur_value, m.change ORDER BY m.change DESC;\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'m.metric_id': 'Revenue', 'm.metric_name': 'Revenue', 'm.cur_value': 500000.0, 'm.change': 10000.0}, {'m.metric_id': 'AOV', 'm.metric_name': 'AOV', 'm.cur_value': 135.8, 'm.change': 12.8}, {'m.metric_id': 'CLTV', 'm.metric_name': 'CLTV', 'm.cur_value': 1500.0, 'm.change': 5.0}, {'m.metric_id': 'PurchaseFrequency', 'm.metric_name': 'PurchaseFrequency', 'm.cur_value': 4.5, 'm.change': 2.2}, {'m.metric_id': 'ChurnRiskScore', 'm.metric_name': 'ChurnRiskScore', 'm.cur_value': 0.12, 'm.change': -1.5}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='give the significant changes in metrics for user 1', additional_kwargs={}, response_metadata={}, id='8c2c8d13-4ea2-4862-9539-6f2d7d9b6a8d'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_9f5a', 'function': {'arguments': '{\"__arg1\":\"changes in metrics for user 1\"}', 'name': 'Kuzu Query Tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 1403, 'total_tokens': 1456, 'completion_time': 0.156249751, 'prompt_time': 0.087662892, 'queue_time': 0.02258013199999999, 'total_time': 0.243912643}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-00b8a0e2-b28a-4754-9dd1-7eab77daba13-0', tool_calls=[{'name': 'Kuzu Query Tool', 'args': {'__arg1': 'changes in metrics for user 1'}, 'id': 'call_9f5a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1403, 'output_tokens': 53, 'total_tokens': 1456}),\n",
       "  ToolMessage(content='Here are the changes in metrics: Revenue changed by 10000.0, AOV changed by 12.8, CLTV changed by 5.0, PurchaseFrequency changed by 2.2, and ChurnRiskScore changed by -1.5.', name='Kuzu Query Tool', id='5bbb7bd4-b5cc-42e3-b695-abff516f962e', tool_call_id='call_9f5a'),\n",
       "  AIMessage(content='Here are the significant changes in metrics for user 1: Revenue changed by 10000.0, AOV changed by 12.8, CLTV changed by 5.0, PurchaseFrequency changed by 2.2, and ChurnRiskScore changed by -1.5.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 1534, 'total_tokens': 1595, 'completion_time': 0.179901282, 'prompt_time': 0.121256849, 'queue_time': 0.585010842, 'total_time': 0.301158131}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None}, id='run-2d871637-c2ce-4960-a768-0b57838ff7a3-0', usage_metadata={'input_tokens': 1534, 'output_tokens': 61, 'total_tokens': 1595})]}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\"messages\": [(\"user\",\"give the significant changes in metrics for user 1\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=1.1990  , p=0.2969  , df_denom=11, df_num=1\n",
      "ssr based chi2 test:   chi2=1.5261  , p=0.2167  , df=1\n",
      "likelihood ratio test: chi2=1.4485  , p=0.2288  , df=1\n",
      "parameter F test:         F=1.1990  , p=0.2969  , df_denom=11, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=2.1091  , p=0.1838  , df_denom=8, df_num=2\n",
      "ssr based chi2 test:   chi2=6.8546  , p=0.0325  , df=2\n",
      "likelihood ratio test: chi2=5.5053  , p=0.0638  , df=2\n",
      "parameter F test:         F=2.1091  , p=0.1838  , df_denom=8, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=2.7233  , p=0.1542  , df_denom=5, df_num=3\n",
      "ssr based chi2 test:   chi2=19.6075 , p=0.0002  , df=3\n",
      "likelihood ratio test: chi2=11.6219 , p=0.0088  , df=3\n",
      "parameter F test:         F=2.7233  , p=0.1542  , df_denom=5, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.9378  , p=0.3537  , df_denom=11, df_num=1\n",
      "ssr based chi2 test:   chi2=1.1936  , p=0.2746  , df=1\n",
      "likelihood ratio test: chi2=1.1454  , p=0.2845  , df=1\n",
      "parameter F test:         F=0.9378  , p=0.3537  , df_denom=11, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.9461  , p=0.4277  , df_denom=8, df_num=2\n",
      "ssr based chi2 test:   chi2=3.0748  , p=0.2149  , df=2\n",
      "likelihood ratio test: chi2=2.7600  , p=0.2516  , df=2\n",
      "parameter F test:         F=0.9461  , p=0.4277  , df_denom=8, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=1.5982  , p=0.3013  , df_denom=5, df_num=3\n",
      "ssr based chi2 test:   chi2=11.5071 , p=0.0093  , df=3\n",
      "likelihood ratio test: chi2=8.0688  , p=0.0446  , df=3\n",
      "parameter F test:         F=1.5982  , p=0.3013  , df_denom=5, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.7572  , p=0.4028  , df_denom=11, df_num=1\n",
      "ssr based chi2 test:   chi2=0.9637  , p=0.3263  , df=1\n",
      "likelihood ratio test: chi2=0.9320  , p=0.3344  , df=1\n",
      "parameter F test:         F=0.7572  , p=0.4028  , df_denom=11, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.5476  , p=0.5986  , df_denom=8, df_num=2\n",
      "ssr based chi2 test:   chi2=1.7797  , p=0.4107  , df=2\n",
      "likelihood ratio test: chi2=1.6679  , p=0.4343  , df=2\n",
      "parameter F test:         F=0.5476  , p=0.5986  , df_denom=8, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.9824  , p=0.4713  , df_denom=5, df_num=3\n",
      "ssr based chi2 test:   chi2=7.0733  , p=0.0696  , df=3\n",
      "likelihood ratio test: chi2=5.5606  , p=0.1351  , df=3\n",
      "parameter F test:         F=0.9824  , p=0.4713  , df_denom=5, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.9121  , p=0.3601  , df_denom=11, df_num=1\n",
      "ssr based chi2 test:   chi2=1.1609  , p=0.2813  , df=1\n",
      "likelihood ratio test: chi2=1.1152  , p=0.2909  , df=1\n",
      "parameter F test:         F=0.9121  , p=0.3601  , df_denom=11, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=1.2647  , p=0.3332  , df_denom=8, df_num=2\n",
      "ssr based chi2 test:   chi2=4.1103  , p=0.1281  , df=2\n",
      "likelihood ratio test: chi2=3.5715  , p=0.1677  , df=2\n",
      "parameter F test:         F=1.2647  , p=0.3332  , df_denom=8, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=2.1402  , p=0.2137  , df_denom=5, df_num=3\n",
      "ssr based chi2 test:   chi2=15.4096 , p=0.0015  , df=3\n",
      "likelihood ratio test: chi2=9.9118  , p=0.0193  , df=3\n",
      "parameter F test:         F=2.1402  , p=0.2137  , df_denom=5, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=2.6776  , p=0.1300  , df_denom=11, df_num=1\n",
      "ssr based chi2 test:   chi2=3.4079  , p=0.0649  , df=1\n",
      "likelihood ratio test: chi2=3.0501  , p=0.0807  , df=1\n",
      "parameter F test:         F=2.6776  , p=0.1300  , df_denom=11, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=1.5287  , p=0.2740  , df_denom=8, df_num=2\n",
      "ssr based chi2 test:   chi2=4.9682  , p=0.0834  , df=2\n",
      "likelihood ratio test: chi2=4.2075  , p=0.1220  , df=2\n",
      "parameter F test:         F=1.5287  , p=0.2740  , df_denom=8, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=3.1936  , p=0.1218  , df_denom=5, df_num=3\n",
      "ssr based chi2 test:   chi2=22.9937 , p=0.0000  , df=3\n",
      "likelihood ratio test: chi2=12.8431 , p=0.0050  , df=3\n",
      "parameter F test:         F=3.1936  , p=0.1218  , df_denom=5, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.7890  , p=0.3934  , df_denom=11, df_num=1\n",
      "ssr based chi2 test:   chi2=1.0042  , p=0.3163  , df=1\n",
      "likelihood ratio test: chi2=0.9698  , p=0.3247  , df=1\n",
      "parameter F test:         F=0.7890  , p=0.3934  , df_denom=11, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.3350  , p=0.7249  , df_denom=8, df_num=2\n",
      "ssr based chi2 test:   chi2=1.0887  , p=0.5802  , df=2\n",
      "likelihood ratio test: chi2=1.0455  , p=0.5929  , df=2\n",
      "parameter F test:         F=0.3350  , p=0.7249  , df_denom=8, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.3786  , p=0.7731  , df_denom=5, df_num=3\n",
      "ssr based chi2 test:   chi2=2.7260  , p=0.4358  , df=3\n",
      "likelihood ratio test: chi2=2.4565  , p=0.4832  , df=3\n",
      "parameter F test:         F=0.3786  , p=0.7731  , df_denom=5, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=0.8870  , p=0.3665  , df_denom=11, df_num=1\n",
      "ssr based chi2 test:   chi2=1.1289  , p=0.2880  , df=1\n",
      "likelihood ratio test: chi2=1.0857  , p=0.2974  , df=1\n",
      "parameter F test:         F=0.8870  , p=0.3665  , df_denom=11, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=0.4662  , p=0.6434  , df_denom=8, df_num=2\n",
      "ssr based chi2 test:   chi2=1.5151  , p=0.4688  , df=2\n",
      "likelihood ratio test: chi2=1.4331  , p=0.4884  , df=2\n",
      "parameter F test:         F=0.4662  , p=0.6434  , df_denom=8, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=0.4993  , p=0.6989  , df_denom=5, df_num=3\n",
      "ssr based chi2 test:   chi2=3.5951  , p=0.3086  , df=3\n",
      "likelihood ratio test: chi2=3.1446  , p=0.3699  , df=3\n",
      "parameter F test:         F=0.4993  , p=0.6989  , df_denom=5, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=1.5353  , p=0.2411  , df_denom=11, df_num=1\n",
      "ssr based chi2 test:   chi2=1.9540  , p=0.1622  , df=1\n",
      "likelihood ratio test: chi2=1.8292  , p=0.1762  , df=1\n",
      "parameter F test:         F=1.5353  , p=0.2411  , df_denom=11, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=1.0667  , p=0.3885  , df_denom=8, df_num=2\n",
      "ssr based chi2 test:   chi2=3.4667  , p=0.1767  , df=2\n",
      "likelihood ratio test: chi2=3.0731  , p=0.2151  , df=2\n",
      "parameter F test:         F=1.0667  , p=0.3885  , df_denom=8, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=2.9001  , p=0.1408  , df_denom=5, df_num=3\n",
      "ssr based chi2 test:   chi2=20.8809 , p=0.0001  , df=3\n",
      "likelihood ratio test: chi2=12.0958 , p=0.0071  , df=3\n",
      "parameter F test:         F=2.9001  , p=0.1408  , df_denom=5, df_num=3\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 1\n",
      "ssr based F test:         F=1.5392  , p=0.2405  , df_denom=11, df_num=1\n",
      "ssr based chi2 test:   chi2=1.9590  , p=0.1616  , df=1\n",
      "likelihood ratio test: chi2=1.8335  , p=0.1757  , df=1\n",
      "parameter F test:         F=1.5392  , p=0.2405  , df_denom=11, df_num=1\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 2\n",
      "ssr based F test:         F=1.0712  , p=0.3871  , df_denom=8, df_num=2\n",
      "ssr based chi2 test:   chi2=3.4815  , p=0.1754  , df=2\n",
      "likelihood ratio test: chi2=3.0847  , p=0.2139  , df=2\n",
      "parameter F test:         F=1.0712  , p=0.3871  , df_denom=8, df_num=2\n",
      "\n",
      "Granger Causality\n",
      "number of lags (no zero) 3\n",
      "ssr based F test:         F=2.9206  , p=0.1393  , df_denom=5, df_num=3\n",
      "ssr based chi2 test:   chi2=21.0282 , p=0.0001  , df=3\n",
      "likelihood ratio test: chi2=12.1494 , p=0.0069  , df=3\n",
      "parameter F test:         F=2.9206  , p=0.1393  , df_denom=5, df_num=3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what caused the change in metric Revenue', additional_kwargs={}, response_metadata={}, id='f40b2c38-3a3a-457e-b6ae-2eac667e5864'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_9hxh', 'function': {'arguments': '{\"__arg1\":\"{\\\\\"metric\\\\\": \\\\\"Revenue\\\\\"}\"}', 'name': 'analyze_similarity_causality_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 1401, 'total_tokens': 1456, 'completion_time': 0.161971716, 'prompt_time': 0.125951915, 'queue_time': 1.6985534070000001, 'total_time': 0.287923631}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_753a4aecf6', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d78cf6e1-d169-4fe2-b370-6050df36e7b9-0', tool_calls=[{'name': 'analyze_similarity_causality_tool', 'args': {'__arg1': '{\"metric\": \"Revenue\"}'}, 'id': 'call_9hxh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1401, 'output_tokens': 55, 'total_tokens': 1456}),\n",
       "  ToolMessage(content='{\"Top 2 Pearson Correlation Variables\": [{\"Variable\": \"Bikes\", \"Pearson Correlation\": 0.9840617178406902}, {\"Variable\": \"Corporate\", \"Pearson Correlation\": 0.9678522571957607}], \"Top 2 Granger Causality Variables\": [{\"Variable\": \"Bikes\", \"Best Granger p-value\": 4.050517689663483e-05}, {\"Variable\": \"Corporate\", \"Best Granger p-value\": 0.00010386756007865527}]}', name='analyze_similarity_causality_tool', id='3f4ea09d-ef99-48a9-a7b6-18aca9068f54', tool_call_id='call_9hxh'),\n",
       "  AIMessage(content='Based on the analysis, the top 2 variables that are correlated with the change in the Revenue metric are Bikes and Corporate. The Pearson correlation coefficient suggests a strong positive correlation between Revenue and Bikes (0.984), and a strong positive correlation between Revenue and Corporate (0.968). Additionally, the Granger causality test suggests that Bikes and Corporate are likely to have a causal relationship with Revenue, with Bikes having a stronger causal relationship (p-value of 4.05e-05) and Corporate having a weaker causal relationship (p-value of 0.000104).', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 121, 'prompt_tokens': 1593, 'total_tokens': 1714, 'completion_time': 0.354995637, 'prompt_time': 0.1025547, 'queue_time': 0.17769508, 'total_time': 0.457550337}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2f30b0b571', 'finish_reason': 'stop', 'logprobs': None}, id='run-d03de125-1cea-4aa2-8a92-49b22db4b092-0', usage_metadata={'input_tokens': 1593, 'output_tokens': 121, 'total_tokens': 1714})]}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\"messages\": [(\"user\",\"what caused the change in metric Revenue\"),\n",
    "                           ]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85789/4064045059.py:61: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, corr_p_value = pearsonr(df_pair.iloc[:, 0], df_pair.iloc[:, 1])\n",
      "/tmp/ipykernel_85789/4064045059.py:61: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, corr_p_value = pearsonr(df_pair.iloc[:, 0], df_pair.iloc[:, 1])\n",
      "/tmp/ipykernel_85789/4064045059.py:61: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, corr_p_value = pearsonr(df_pair.iloc[:, 0], df_pair.iloc[:, 1])\n",
      "/tmp/ipykernel_85789/4064045059.py:61: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, corr_p_value = pearsonr(df_pair.iloc[:, 0], df_pair.iloc[:, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new KuzuQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (m:Metrics {LOWER(metric_name): 'aov'}) RETURN m.cur_value, m.change, m.trend, m.goal\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what caused the change in metric AOV', additional_kwargs={}, response_metadata={}, id='a981e05b-5498-4ec3-8ab0-8cbe17d1e39f'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_nvbk', 'function': {'arguments': '{\"__arg1\":\"{\\\\\"metric\\\\\": \\\\\"AOV\\\\\"}\"}', 'name': 'analyze_similarity_causality_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 1402, 'total_tokens': 1457, 'completion_time': 0.19092022, 'prompt_time': 0.065710045, 'queue_time': 0.22743977799999998, 'total_time': 0.256630265}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2e0feca3c9', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-a67c3c00-122d-4a49-a6f1-341482e2c237-0', tool_calls=[{'name': 'analyze_similarity_causality_tool', 'args': {'__arg1': '{\"metric\": \"AOV\"}'}, 'id': 'call_nvbk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1402, 'output_tokens': 55, 'total_tokens': 1457}),\n",
       "  ToolMessage(content=\"Error: KeyError('Pearson Correlation')\\n Please fix your mistakes.\", name='analyze_similarity_causality_tool', id='0edf574c-8434-4829-a99b-3a9ee6dd1d61', tool_call_id='call_nvbk', status='error'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fj44', 'function': {'arguments': '{\"__arg1\":\"{\\\\\"metric\\\\\": \\\\\"AOV\\\\\"}\"}', 'name': 'analyze_similarity_causality_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 1489, 'total_tokens': 1535, 'completion_time': 0.131428571, 'prompt_time': 0.072026968, 'queue_time': 0.247343634, 'total_time': 0.203455539}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2e0feca3c9', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-7c77626a-4eaa-4c25-90a0-3843149d5239-0', tool_calls=[{'name': 'analyze_similarity_causality_tool', 'args': {'__arg1': '{\"metric\": \"AOV\"}'}, 'id': 'call_fj44', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1489, 'output_tokens': 46, 'total_tokens': 1535}),\n",
       "  ToolMessage(content=\"Error: KeyError('Pearson Correlation')\\n Please fix your mistakes.\", name='analyze_similarity_causality_tool', id='43afdf9e-b7e2-4b81-b1c3-69b3f3808452', tool_call_id='call_fj44', status='error'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_cjxd', 'function': {'arguments': '{\"__arg1\":\"{\\\\\"metric\\\\\": \\\\\"AOV\\\\\"}\"}', 'name': 'analyze_similarity_causality_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 1578, 'total_tokens': 1627, 'completion_time': 0.177763572, 'prompt_time': 0.079846502, 'queue_time': 0.242502559, 'total_time': 0.257610074}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2e0feca3c9', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3104d27a-7483-4718-8978-71f54e51d837-0', tool_calls=[{'name': 'analyze_similarity_causality_tool', 'args': {'__arg1': '{\"metric\": \"AOV\"}'}, 'id': 'call_cjxd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1578, 'output_tokens': 49, 'total_tokens': 1627}),\n",
       "  ToolMessage(content=\"Error: KeyError('Pearson Correlation')\\n Please fix your mistakes.\", name='analyze_similarity_causality_tool', id='59b14fbc-67d1-4938-975a-912207a48dcb', tool_call_id='call_cjxd', status='error'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mjyp', 'function': {'arguments': '{\"__arg1\":\"{\\\\\"metric\\\\\": \\\\\"AOV\\\\\"}\"}', 'name': 'analyze_similarity_causality_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 1667, 'total_tokens': 1741, 'completion_time': 0.29712909, 'prompt_time': 0.079291429, 'queue_time': 0.25895730000000006, 'total_time': 0.376420519}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2e0feca3c9', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-bfae2041-ae74-415b-8ade-dac2bc1e010c-0', tool_calls=[{'name': 'analyze_similarity_causality_tool', 'args': {'__arg1': '{\"metric\": \"AOV\"}'}, 'id': 'call_mjyp', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1667, 'output_tokens': 74, 'total_tokens': 1741}),\n",
       "  ToolMessage(content=\"Error: KeyError('Pearson Correlation')\\n Please fix your mistakes.\", name='analyze_similarity_causality_tool', id='6c2faa10-3276-419f-b42e-8763acbd3071', tool_call_id='call_mjyp', status='error'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_hzrk', 'function': {'arguments': '{\"__arg1\":\"{\\\\\"query\\\\\": \\\\\"What happened to metric AOV?\\\\\"}\"}', 'name': 'Kuzu Query Tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 1756, 'total_tokens': 1843, 'completion_time': 0.327804608, 'prompt_time': 0.079544227, 'queue_time': 0.244325594, 'total_time': 0.407348835}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2e0feca3c9', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c4191d18-f332-42b9-8c21-e80d772b9f03-0', tool_calls=[{'name': 'Kuzu Query Tool', 'args': {'__arg1': '{\"query\": \"What happened to metric AOV?\"}'}, 'id': 'call_hzrk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1756, 'output_tokens': 87, 'total_tokens': 1843}),\n",
       "  ToolMessage(content='Error: RuntimeError(\\'Parser exception: Invalid input <MATCH (m:Metrics {LOWER(>: expected rule oC_SingleQuery (line: 1, offset: 23)\\\\n\"MATCH (m:Metrics {LOWER(metric_name): \\\\\\'aov\\\\\\'}) RETURN m.cur_value, m.change, m.trend, m.goal\"\\\\n                        ^\\')\\n Please fix your mistakes.', name='Kuzu Query Tool', id='2178cbca-9840-4bc1-89bd-35a18bbfb7a9', tool_call_id='call_hzrk', status='error'),\n",
       "  AIMessage(content='I apologize for the mistake. It seems that the query is not correctly formatted. I\\'ll try again with a different approach.\\n\\nSince the error persists, I\\'ll respond directly without using a tool.\\n\\nCan you please provide more context or information about what you mean by \"what caused the change in metric AOV\"? Are you looking for a specific time period or dimension?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 1910, 'total_tokens': 1984, 'completion_time': 0.360569712, 'prompt_time': 0.085520448, 'queue_time': 0.26591204, 'total_time': 0.44609016}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_2e0feca3c9', 'finish_reason': 'stop', 'logprobs': None}, id='run-0de94ce9-355e-40dc-b2db-5a48a077231c-0', usage_metadata={'input_tokens': 1910, 'output_tokens': 74, 'total_tokens': 1984})]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\"messages\": [(\"user\",\"what caused the change in metric AOV\"),\n",
    "                           ]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
